{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c3441d-e8e1-40f1-956b-573dc1316fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta, date, datetime\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a6c9d",
   "metadata": {},
   "source": [
    "## Data\n",
    "Here is where you can download the data from EPA: https://www.epa.gov/outdoor-air-quality-data/download-daily-data\n",
    "\n",
    "Select: \n",
    "- Pollutant = PM2.5\n",
    "- Year = 2020 thru 2024 (individual downloads for each, sigh)\n",
    "- Geographic Area = Houston - The Woodlands - Sugar Land CBSA + All Sites\n",
    "\n",
    "You can see from the codeblock below that subsequent downloads of past data aren't always identical, telling me that they likely continue to update values long after the dates have passed. So just download files fresh every time you're doing this. I would assume the further back you go, the less likely things are to change but... again... I'm not wasting time on inspecting that now.\n",
    "\n",
    "## Process\n",
    "We're looking for monitors that are over 9 and 12 Âµg/m3 (new and old EPA limits). You take the annual average concentration for each monitor, then you take the average of those annual averages over 3-year periods. If the 3-year avg is over the concentration limit, then we flag the place. Here's [an EPA source](https://experience.arcgis.com/experience/a2ca272ce9fc4019a88ce35b863e2cab#data_s=id%3AdataSource_1-18a8e80642b-layer-19-19147d8da1c-layer-32%3A951) we can use to compare 3-year values for each monitor for fact-checking purposes.\n",
    "\n",
    "- Remove days known to have high pollution not from industry: NYE, 4th of July\n",
    "- Group by `Site ID` and `Daily Mean PM2.5 Concentration` and `year` to get annual average concentration for each site, for each year \n",
    "- Further group by `Site ID` and `Daily Mean PM2.5 Concentration` and `avgAnnualConc` to calculate 3-year average for timespans 2018-20, 2019-21, 2020-22, 2021-23, 2022-24\n",
    "- On this grouped data, calculate how many of the past 3-year groupings the site has been higher than current 9 limit\n",
    "- On this grouped data, calculate how many of the past 3-year groupings the site has been higher than past 12 limit\n",
    "- On your daily data, calculate how many days per year each site had daily averages higher than 35\n",
    "- Join grouped data to daily overage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f10dbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4964\n",
      "4964\n",
      "9928\n",
      "4978\n"
     ]
    }
   ],
   "source": [
    "#just checking to make sure the 2023 data didn't change between now and the\n",
    "#last time I downloaded it.\n",
    "base_path = '../data/source/EPA/'\n",
    "file_suffix = '_houmetro_epa_ad_viz_plotval_data'\n",
    "\n",
    "df2023 = pd.read_csv(f'{base_path}2023{file_suffix}.csv')\n",
    "df2023v2 = pd.read_csv(f'{base_path}2023v2{file_suffix}.csv')\n",
    "\n",
    "print(len(df2023))\n",
    "print(len(df2023v2))\n",
    "\n",
    "#combine then dedup to see if they are the same\n",
    "df2023combo = pd.concat([df2023, df2023v2])\n",
    "\n",
    "print(len(df2023combo))\n",
    "\n",
    "df2023combo.drop_duplicates(inplace=True)\n",
    "\n",
    "#ok i don't actually care right now what the differences are. I just need to know\n",
    "#that there are differences so i'm going to just download all the files i need\n",
    "#fresh everytime i run this script.\n",
    "print(len(df2023combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd7879c-177b-44e1-a317-f6726bef9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/source/EPA/'\n",
    "file_suffix = '_houmetro_epa_ad_viz_plotval_data'\n",
    "\n",
    "years = range(2018, 2025)\n",
    "pm25_dfs = []\n",
    "for year in years:\n",
    "    df = pd.read_csv(f'{base_path}{year}{file_suffix}.csv')\n",
    "    df['datetime'] = pd.to_datetime(df['Date'])\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    pm25_dfs.append(df)\n",
    "    \n",
    "pm25 = pd.concat(pm25_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e5a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                                      object\n",
      "Source                                    object\n",
      "Site ID                                    int64\n",
      "POC                                        int64\n",
      "Daily Mean PM2.5 Concentration           float64\n",
      "Units                                     object\n",
      "Daily AQI Value                            int64\n",
      "Local Site Name                           object\n",
      "Daily Obs Count                            int64\n",
      "Percent Complete                         float64\n",
      "AQS Parameter Code                         int64\n",
      "AQS Parameter Description                 object\n",
      "Method Code                              float64\n",
      "Method Description                        object\n",
      "CBSA Code                                  int64\n",
      "CBSA Name                                 object\n",
      "State FIPS Code                            int64\n",
      "State                                     object\n",
      "County FIPS Code                           int64\n",
      "County                                    object\n",
      "Site Latitude                            float64\n",
      "Site Longitude                           float64\n",
      "datetime                          datetime64[ns]\n",
      "year                                       int32\n",
      "dtype: object\n",
      "2018-01-01 00:00:00\n",
      "2024-12-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>POC</th>\n",
       "      <th>Daily Mean PM2.5 Concentration</th>\n",
       "      <th>Units</th>\n",
       "      <th>Daily AQI Value</th>\n",
       "      <th>Local Site Name</th>\n",
       "      <th>Daily Obs Count</th>\n",
       "      <th>Percent Complete</th>\n",
       "      <th>AQS Parameter Code</th>\n",
       "      <th>AQS Parameter Description</th>\n",
       "      <th>Method Code</th>\n",
       "      <th>Method Description</th>\n",
       "      <th>CBSA Code</th>\n",
       "      <th>CBSA Name</th>\n",
       "      <th>State FIPS Code</th>\n",
       "      <th>State</th>\n",
       "      <th>County FIPS Code</th>\n",
       "      <th>County</th>\n",
       "      <th>Site Latitude</th>\n",
       "      <th>Site Longitude</th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/02/2018</td>\n",
       "      <td>AQS</td>\n",
       "      <td>481671034</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ug/m3 LC</td>\n",
       "      <td>26</td>\n",
       "      <td>Galveston 99th Street</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88101</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>145.0</td>\n",
       "      <td>R &amp; P Model 2025 PM-2.5 Sequential Air Sampler...</td>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>167</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>29.254474</td>\n",
       "      <td>-94.861289</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/08/2018</td>\n",
       "      <td>AQS</td>\n",
       "      <td>481671034</td>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>ug/m3 LC</td>\n",
       "      <td>39</td>\n",
       "      <td>Galveston 99th Street</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88101</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>145.0</td>\n",
       "      <td>R &amp; P Model 2025 PM-2.5 Sequential Air Sampler...</td>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>167</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>29.254474</td>\n",
       "      <td>-94.861289</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/14/2018</td>\n",
       "      <td>AQS</td>\n",
       "      <td>481671034</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>ug/m3 LC</td>\n",
       "      <td>19</td>\n",
       "      <td>Galveston 99th Street</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88101</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>145.0</td>\n",
       "      <td>R &amp; P Model 2025 PM-2.5 Sequential Air Sampler...</td>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>167</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>29.254474</td>\n",
       "      <td>-94.861289</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/20/2018</td>\n",
       "      <td>AQS</td>\n",
       "      <td>481671034</td>\n",
       "      <td>1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>ug/m3 LC</td>\n",
       "      <td>26</td>\n",
       "      <td>Galveston 99th Street</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88101</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>145.0</td>\n",
       "      <td>R &amp; P Model 2025 PM-2.5 Sequential Air Sampler...</td>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>167</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>29.254474</td>\n",
       "      <td>-94.861289</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/26/2018</td>\n",
       "      <td>AQS</td>\n",
       "      <td>481671034</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>ug/m3 LC</td>\n",
       "      <td>36</td>\n",
       "      <td>Galveston 99th Street</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88101</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>145.0</td>\n",
       "      <td>R &amp; P Model 2025 PM-2.5 Sequential Air Sampler...</td>\n",
       "      <td>26420</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>167</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>29.254474</td>\n",
       "      <td>-94.861289</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Source    Site ID  POC  Daily Mean PM2.5 Concentration  \\\n",
       "0  01/02/2018    AQS  481671034    1                             4.7   \n",
       "1  01/08/2018    AQS  481671034    1                             7.1   \n",
       "2  01/14/2018    AQS  481671034    1                             3.4   \n",
       "3  01/20/2018    AQS  481671034    1                             4.6   \n",
       "4  01/26/2018    AQS  481671034    1                             6.4   \n",
       "\n",
       "      Units  Daily AQI Value        Local Site Name  Daily Obs Count  \\\n",
       "0  ug/m3 LC               26  Galveston 99th Street                1   \n",
       "1  ug/m3 LC               39  Galveston 99th Street                1   \n",
       "2  ug/m3 LC               19  Galveston 99th Street                1   \n",
       "3  ug/m3 LC               26  Galveston 99th Street                1   \n",
       "4  ug/m3 LC               36  Galveston 99th Street                1   \n",
       "\n",
       "   Percent Complete  AQS Parameter Code AQS Parameter Description  \\\n",
       "0             100.0               88101  PM2.5 - Local Conditions   \n",
       "1             100.0               88101  PM2.5 - Local Conditions   \n",
       "2             100.0               88101  PM2.5 - Local Conditions   \n",
       "3             100.0               88101  PM2.5 - Local Conditions   \n",
       "4             100.0               88101  PM2.5 - Local Conditions   \n",
       "\n",
       "   Method Code                                 Method Description  CBSA Code  \\\n",
       "0        145.0  R & P Model 2025 PM-2.5 Sequential Air Sampler...      26420   \n",
       "1        145.0  R & P Model 2025 PM-2.5 Sequential Air Sampler...      26420   \n",
       "2        145.0  R & P Model 2025 PM-2.5 Sequential Air Sampler...      26420   \n",
       "3        145.0  R & P Model 2025 PM-2.5 Sequential Air Sampler...      26420   \n",
       "4        145.0  R & P Model 2025 PM-2.5 Sequential Air Sampler...      26420   \n",
       "\n",
       "                              CBSA Name  State FIPS Code  State  \\\n",
       "0  Houston-The Woodlands-Sugar Land, TX               48  Texas   \n",
       "1  Houston-The Woodlands-Sugar Land, TX               48  Texas   \n",
       "2  Houston-The Woodlands-Sugar Land, TX               48  Texas   \n",
       "3  Houston-The Woodlands-Sugar Land, TX               48  Texas   \n",
       "4  Houston-The Woodlands-Sugar Land, TX               48  Texas   \n",
       "\n",
       "   County FIPS Code     County  Site Latitude  Site Longitude   datetime  year  \n",
       "0               167  Galveston      29.254474      -94.861289 2018-01-02  2018  \n",
       "1               167  Galveston      29.254474      -94.861289 2018-01-08  2018  \n",
       "2               167  Galveston      29.254474      -94.861289 2018-01-14  2018  \n",
       "3               167  Galveston      29.254474      -94.861289 2018-01-20  2018  \n",
       "4               167  Galveston      29.254474      -94.861289 2018-01-26  2018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pm25.dtypes)\n",
    "print(pm25.datetime.min())\n",
    "print(pm25.datetime.max())\n",
    "display(pm25.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f6e14",
   "metadata": {},
   "source": [
    "- Remove days known to have high pollution not from industry: NYE, 4th of July\n",
    "- Group by `Site ID` and `Daily Mean PM2.5 Concentration` and `year` to get annual average concentration for each site, for each year \n",
    "- Further group by `Site ID` and `Daily Mean PM2.5 Concentration` to calculate 3-year average for timespans 2018-20, 2019-21, 2020-22, 2021-23, 2022-24\n",
    "- On this grouped data, calculate how many of the past 3-year groupings the site has been higher than current 9 limit\n",
    "- On this grouped data, calculate how many of the past 3-year groupings the site has been higher than past 12 limit\n",
    "- On your daily data, calculate how many days per year each site had daily averages higher than 35\n",
    "- Join grouped data to daily overage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4efdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/mqj0d6v95vbfcqgf7kpgrsrc0000gr/T/ipykernel_3927/3434297536.py:10: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  pm25 = pm25.loc[~pm25['datetime'].isin(holidays)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Site ID', '2018', '2019', '2020', '2021', '2022', '2023', '2024',\n",
       "       'avg2018_20', 'avg2019_21', 'avg2020_22', 'avg2021_23', 'avg2022_24',\n",
       "       'yrs_over12', 'yrs_over9', 'over35', 'max_read', 'min_read', 'min_date',\n",
       "       'max_date', 'daily_cnt', 'County FIPS Code', 'County', 'Site Latitude',\n",
       "       'Site Longitude'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remove days known to have high pollution not from industry: NYE, 4th of July\n",
    "holidays = ['2018-01-01','2018-07-04','2018-12-31',\n",
    "            '2019-01-01','2019-07-04','2019-12-31',\n",
    "            '2020-01-01','2020-07-04','2020-12-31',\n",
    "            '2021-01-01','2021-07-04','2021-12-31',\n",
    "            '2022-01-01','2022-07-04','2022-12-31',\n",
    "            '2023-01-01','2023-07-04','2023-12-31',\n",
    "            '2024-01-01','2024-07-04','2024-12-31']\n",
    "\n",
    "pm25 = pm25.loc[~pm25['datetime'].isin(holidays)]\n",
    "\n",
    "#Group by `Site ID` and `year` to get annual average `Daily Mean PM2.5 Concentration` for each site, for each year\n",
    "by_site = pm25.groupby(['Site ID', 'year'])['Daily Mean PM2.5 Concentration'].mean().reset_index()\n",
    "\n",
    "#Further group by `Site ID` and `Daily Mean PM2.5 Concentration` to calculate 3-year average for timespans \n",
    "# 2018-20, 2019-21, 2020-22, 2021-23, 2022-24\n",
    "by_yr = pd.pivot_table(by_site, index='Site ID', columns='year', \n",
    "                       values='Daily Mean PM2.5 Concentration', aggfunc='mean').reset_index()\n",
    "by_yr['avg2018_20'] = by_yr[[2018, 2019, 2020]].mean(axis=1,skipna=False)\n",
    "by_yr['avg2019_21'] = by_yr[[2019, 2020, 2021]].mean(axis=1,skipna=False)\n",
    "by_yr['avg2020_22'] = by_yr[[2020, 2021, 2022]].mean(axis=1,skipna=False)\n",
    "by_yr['avg2021_23'] = by_yr[[2021, 2022, 2023]].mean(axis=1,skipna=False)\n",
    "by_yr['avg2022_24'] = by_yr[[2022, 2023, 2024]].mean(axis=1,skipna=False)\n",
    "\n",
    "#calculate how many of the past years the site has been higher than current and past limits\n",
    "def over_limit(x, limit):\n",
    "    return (x > limit).sum()\n",
    "\n",
    "def return_max_min(x,limit_type):\n",
    "    measure = 'max'\n",
    "    if limit_type == 'max':\n",
    "        measure = x.max()\n",
    "    elif limit_type == 'min':\n",
    "        measure = x.min()\n",
    "    max_fmt = measure.strftime('%B %Y')\n",
    "    #print(limit_type,':',max_fmt)\n",
    "    return max_fmt\n",
    "\n",
    "over_cols = list(range(2018,2025))\n",
    "by_yr['yrs_over12'] = by_yr[over_cols].apply(lambda x: over_limit(x,12), axis=1)\n",
    "by_yr['yrs_over9'] = by_yr[over_cols].apply(lambda x: over_limit(x,9), axis=1)\n",
    "\n",
    "#calculate how many days per year each site had daily averages higher than 35\n",
    "daily_over35 = pm25.groupby('Site ID').agg(days_over35=('Daily Mean PM2.5 Concentration', lambda x: over_limit(x, 35)),\n",
    "                                           max_value=('Daily Mean PM2.5 Concentration', 'max'),\n",
    "                                           min_value=('Daily Mean PM2.5 Concentration', 'min')\n",
    "                                        ).reset_index()\n",
    "\n",
    "daily_over35 = pm25.groupby('Site ID').agg(over35=('Daily Mean PM2.5 Concentration', lambda x: over_limit(x, 35)),\n",
    "                                                   max_read=('Daily Mean PM2.5 Concentration', 'max'),\n",
    "                                                   min_read=('Daily Mean PM2.5 Concentration', 'min'),\n",
    "                                                   min_date=('datetime',lambda x: return_max_min(x,'min')),\n",
    "                                                   max_date=('datetime',lambda x: return_max_min(x,'max')),\n",
    "                                                   daily_cnt=('Daily Mean PM2.5 Concentration','count')\n",
    "                                                   ).reset_index()\n",
    "\n",
    "pm25_site_summary = by_yr.merge(daily_over35, on='Site ID', how='left')\n",
    "\n",
    "#lets also join with the sensor features we have\n",
    "site_info = pm25[['Site ID','County FIPS Code', 'County', 'Site Latitude', 'Site Longitude']].drop_duplicates()\n",
    "pm25_site_summary = pm25_site_summary.merge(site_info, on='Site ID', how='left')\n",
    "pm25_site_summary.columns = pm25_site_summary.columns.astype(str)\n",
    "\n",
    "display(pm25_site_summary.columns)\n",
    "\n",
    "#if the 2024 values is greater than 9, list \"out\" for compliance else \"in\"\n",
    "pm25_site_summary['compliance_2024'] = pm25_site_summary['2024'].apply(lambda x: 'out' if x > 9 else 'in')\n",
    "\n",
    "#renaming some columns because i'm anal\n",
    "rename_cols = {'Site ID':'site_id','County FIPS Code':'cnty_fips','County':'county',\n",
    "               'Site Latitude':'latitude','Site Longitude':'longitude'}\n",
    "pm25_site_summary.rename(columns=rename_cols,inplace=True)\n",
    "\n",
    "#export for graphics and whatnot\n",
    "pm25_site_summary['monitor_type'] = 'EPA'\n",
    "pm25_site_summary.rename(columns={'2018':'avg_2018',\n",
    "                                  '2019':'avg_2019',\n",
    "                                  '2020':'avg_2020',\n",
    "                                  '2021':'avg_2021',\n",
    "                                  '2022':'avg_2022',\n",
    "                                  '2023':'avg_2023',\n",
    "                                  '2024':'avg_2024'},inplace=True)\n",
    "\n",
    "reorder_cols = ['longitude','latitude','site_id', 'avg_2022', 'avg_2023', 'avg_2024', \n",
    "                'avg2022_24', 'yrs_over12','yrs_over9', 'over35', 'max_read', 'min_read', \n",
    "                'cnty_fips','county','monitor_type','compliance_2024','min_date',\n",
    "                'max_date','daily_cnt']\n",
    "pm25_site_summary[reorder_cols].to_csv('../data/analyzed/houmetro-epa-pm25-site-summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e10035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm25_site_summary.columns)\n",
    "display(pm25_site_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#482010046 is Settegast\n",
    "pm25.loc[pm25['Site ID'] == 482010046].sort_values('datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d68e1",
   "metadata": {},
   "source": [
    "### Is an average of averages the same as the average of all of the raw values? Let's test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cfb8702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site ID</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>482011035</td>\n",
       "      <td>5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>482011039</td>\n",
       "      <td>3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>482010024</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>482010058</td>\n",
       "      <td>2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>482011034</td>\n",
       "      <td>2408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Site ID  counts\n",
       "8  482011035    5255\n",
       "9  482011039    3925\n",
       "2  482010024    2700\n",
       "5  482010058    2430\n",
       "7  482011034    2408"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site ID</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>482010046</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>482011050</td>\n",
       "      <td>2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>482010066</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>481671034</td>\n",
       "      <td>2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>482010024</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Site ID  counts\n",
       "3   482010046    1248\n",
       "10  482011050    2357\n",
       "6   482010066    1281\n",
       "1   481671034    2301\n",
       "2   482010024    2700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get some example site_ids\n",
    "display(pm25.groupby(['Site ID']).size().reset_index(name='counts').sort_values('counts', ascending=False).head())\n",
    "display(pm25.groupby(['Site ID']).size().reset_index(name='counts').sort_values('counts', ascending=False).sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43fcaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_avg_types(example_id):\n",
    "    ex_site = pm25.loc[pm25['Site ID'] == example_id]\n",
    "    ex_site_18_20 = ex_site.loc[(ex_site['year'] >= 2018) & (ex_site['year'] <= 2020)]\n",
    "    \n",
    "    value_mean = ex_site_18_20['Daily Mean PM2.5 Concentration'].mean()\n",
    "    avg_avg = pm25_site_summary.loc[pm25_site_summary['site_id'] == example_id]['avg2018_20'].values[0]\n",
    "    \n",
    "    print(round(value_mean,2),'vs',round(avg_avg,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "004241bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.11 vs 10.11\n",
      "8.07 vs 8.16\n",
      "10.42 vs 10.41\n",
      "6.72 vs 6.83\n",
      "9.4 vs 9.39\n",
      "7.33 vs 7.3\n"
     ]
    }
   ],
   "source": [
    "compare_avg_types(482011035)\n",
    "compare_avg_types(482011039)\n",
    "compare_avg_types(482011052)\n",
    "compare_avg_types(481671034)\n",
    "compare_avg_types(482010024)\n",
    "compare_avg_types(482011050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbf7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
