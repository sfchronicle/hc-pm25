{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import json\n",
    "from datetime import timedelta, date\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a list of indoor monitors, for your edification\n",
    "site_info = pd.read_csv('../GIS/purpleair/houmetro-pa-sensors-atleast_1yr.csv')\n",
    "indoor_sensor_list = site_info[site_info['location_type'] == 1]['sensor_index'].tolist()\n",
    "indoor_sensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data we fetched from get-historical-purple-air.ipynb\n",
    "pa_pm25 = pd.read_csv('../data/analyzed/purpleair/houmetro-pa-2022-2024-pm25.csv')\n",
    "\n",
    "#there are dups in the data... i'll figure it out in the pull code but for now lets remove\n",
    "print('pre dedupe:',len(pa_pm25))\n",
    "pa_pm25 = pa_pm25.drop_duplicates()\n",
    "print('post dedupe:',len(pa_pm25))\n",
    "\n",
    "#add a readable date\n",
    "pa_pm25['date'] = pd.to_datetime(pa_pm25['time_stamp'],unit='s')\n",
    "pa_pm25['year'] = pa_pm25['date'].dt.year\n",
    "\n",
    "#need to do the PM2.5 conversion per Lance Wallace's comments\n",
    "pa_pm25['pm2.5_alt_a_ADJ'] = pa_pm25['pm2.5_alt_a']*(3.4/3.0)\n",
    "pa_pm25['pm2.5_alt_b_ADJ'] = pa_pm25['pm2.5_alt_b']*(3.4/3.0)\n",
    "pa_pm25['pm2.5_alt_ADJ'] = pa_pm25[['pm2.5_alt_a_ADJ','pm2.5_alt_b_ADJ']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove days known to have high pollution not from industry: NYE, 4th of July\n",
    "holidays = ['2018-01-01','2018-07-04','2018-12-31',\n",
    "            '2019-01-01','2019-07-04','2019-12-31',\n",
    "            '2020-01-01','2020-07-04','2020-12-31',\n",
    "            '2021-01-01','2021-07-04','2021-12-31',\n",
    "            '2022-01-01','2022-07-04','2022-12-31',\n",
    "            '2023-01-01','2023-07-04','2023-12-31',\n",
    "            '2024-01-01','2024-07-04','2024-12-31',]\n",
    "\n",
    "pa_pm25 = pa_pm25.loc[~pa_pm25['date'].isin(holidays)]\n",
    "print('post holiday remove:',len(pa_pm25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_site = pa_pm25.groupby(['sensor_index','year']).agg(value_cnt=('time_stamp','count'),\n",
    "                                                       pm25_avg=('pm2.5_alt_ADJ','mean')\n",
    "                                                       ).reset_index()\n",
    "\n",
    "#get rid of rows where the sensor didn't report at least 50% of the time\n",
    "by_site_full = by_site.loc[by_site['value_cnt'] >= 0.5*365]\n",
    "\n",
    "by_yr = pd.pivot_table(by_site_full,index='sensor_index',\n",
    "                       columns='year',values='pm25_avg',aggfunc='mean').reset_index()\n",
    "by_yr['avg2022_24'] = by_yr[[2022, 2023, 2024]].mean(axis=1,skipna=False)\n",
    "\n",
    "#calculate how many of the past years the site has been higher than current and past limits\n",
    "def over_limit(x, limit):\n",
    "    return (x > limit).sum()\n",
    "\n",
    "over_cols = [2022,2023,2024]\n",
    "by_yr['yrs_over12'] = by_yr[over_cols].apply(lambda x: over_limit(x,12), axis=1)\n",
    "by_yr['yrs_over9'] = by_yr[over_cols].apply(lambda x: over_limit(x,9), axis=1)\n",
    "\n",
    "#calculate how many days per year each site had daily averages higher than 35\n",
    "daily_over35 = pa_pm25.groupby('sensor_index').agg(days_over35=('pm2.5_alt_ADJ', lambda x: over_limit(x, 35)),\n",
    "                                                   max_value=('pm2.5_alt_ADJ', 'max'),\n",
    "                                                   min_value=('pm2.5_alt_ADJ', 'min')\n",
    "                                                   ).reset_index()\n",
    "\n",
    "pm25_site_summary = by_yr.merge(daily_over35, on='sensor_index', how='left')\n",
    "\n",
    "#lets also join with the sensor features we have\n",
    "site_info = pd.read_csv('../GIS/purpleair/houmetro-pa-sensors-atleast_1yr.csv')\n",
    "site_info.rename(columns={'date':'sensor_created_date'},inplace=True)\n",
    "pm25_site_summary = pm25_site_summary.merge(site_info[['sensor_index','cnty_fips','cnty_nm',\n",
    "                                                       'latitude','longitude','location_type',\n",
    "                                                       'sensor_created_date']],on='sensor_index',how='outer')\n",
    "\n",
    "#remove indoor monitors for this analysis\n",
    "pm25_site_summary = pm25_site_summary.loc[pm25_site_summary['location_type'] == 0]\n",
    "\n",
    "#remove rows that don't have any data\n",
    "#i checked to make sure empty max_value meant no other data in the row\n",
    "pm25_site_summary = pm25_site_summary.loc[~pm25_site_summary['max_value'].isna()]\n",
    "\n",
    "#let's make the columns agree with the EPA monitors\n",
    "rename_cols = {'sensor_index':'site_id','Site Latitude':'latitude','Site Longitude':'longitude'}\n",
    "pm25_site_summary.rename(columns=rename_cols, inplace=True)\n",
    "pm25_site_summary.columns = [ str(x) for x in pm25_site_summary.columns ]\n",
    "\n",
    "\n",
    "#export purpleair\n",
    "pm25_site_summary['monitor_type'] = 'PurpleAir'\n",
    "pm25_site_summary.to_csv('../data/analyzed/houmetro-purpleair-pm25-site-summary.csv',index=False)\n",
    "\n",
    "#concat with EPA data and save too\n",
    "epa_pm25 = pd.read_csv('../data/analyzed/houmetro-epa-pm25-site-summary.csv')\n",
    "combo_pm25 = pd.concat([pm25_site_summary,epa_pm25])\n",
    "reorder_cols = ['longitude','latitude','site_id', '2018','2019', '2020', '2021','2022', '2023', '2024', \n",
    "                'avg2018_19', 'avg2019_21', 'avg2020_22','avg2021_23','avg2022_24', \n",
    "                'yrs_over12','yrs_over9', 'days_over35', 'max_value', 'min_value', \n",
    "                'cnty_fips','county','monitor_type','sensor_created_date']\n",
    "combo_pm25[reorder_cols].to_csv('../data/analyzed/houmetro-epa-purpleair-pm25-site-summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just a couple of integrity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not all the points we pulled data for made it into the final data summary\n",
    "print(len(pm25_site_summary.loc[pm25_site_summary['max_value'].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_site_summary.loc[pm25_site_summary['max_value'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#that's cause I ditched monitors that didn't have at least 182 days of data (50% of the year)\n",
    "#here's an example of not enough data to calculate an annual avg.\n",
    "\n",
    "display(by_site.loc[by_site['value_cnt']<182].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PA monitors with data:',len(by_site.sensor_index.unique()))\n",
    "print('PA monitors with enough data:',len(pm25_site_summary.loc[~pm25_site_summary['max_value'].isna()]))\n",
    "print('EPA monitors:',len(epa_pm25))\n",
    "print('EPA + PA monitors for map:',len(combo_pm25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm25_site_summary.columns)\n",
    "display(pm25_site_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combo_pm25[reorder_cols].columns)\n",
    "display(combo_pm25[reorder_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
