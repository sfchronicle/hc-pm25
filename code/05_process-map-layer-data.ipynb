{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're trying to make a searchable map with one static layer and 3 toggle layers. \n",
    "\n",
    "Static layer = air quality monitors (both regulatory and PurpleAir), styled by 3-yr avg. PM2.5 reading\n",
    "\n",
    "Toggle layers:\n",
    "- life expectancy by tract\n",
    "- asthma by tract\n",
    "- POC or poverty by tract\n",
    "\n",
    "Steps:\n",
    "- pull 2020 and 2010 tracts shapefile\n",
    "- restrict to just Houston metro\n",
    "- pull asthma data from [CDC PLACES](https://data.cdc.gov/500-Cities-Places/PLACES-Local-Data-for-Better-Health-Census-Tract-D/cwsq-ngmh/about_data)\n",
    "- pull most recent POC/poverty from Census API\n",
    "- pull life expectancy [from CDC](https://data.cdc.gov/NCHS/U-S-Life-Expectancy-at-Birth-by-State-and-Census-T/5h56-n989/about_data) - note, this uses the 2010 tracts\n",
    "- join data files to shapes and export\n",
    "- simplify geojson files in mapshaper by 20%\n",
    "- upload manually to sfc fileserver so you don't need to change filepath in searchable map every damn time you update the data (`tx-data/hc-pm25`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#load geos\n",
    "########################################\n",
    "\n",
    "houmetro_cntys = {'Fort Bend, TX':'48157','San Jacinto, TX':'48407','Waller, TX':'48473',\n",
    "                'Galveston, TX':'48167','Harris, TX':'48201','Liberty, TX':'48291',\n",
    "                'Chambers, TX':'48071','Brazoria, TX':'48039','Austin, TX':'48015',\n",
    "                'Montgomery, TX':'48339'}\n",
    "houmetro_cntys_swap = {v: k for k, v in houmetro_cntys.items()}\n",
    "houmetro_fips_ints = [ int(x) for x in list(houmetro_cntys.values()) ]\n",
    "houmetro_fips_strs = [ str(x) for x in list(houmetro_cntys.values()) ]\n",
    "houmetro_nms = [ str(x) for x in list(houmetro_cntys.keys()) ]\n",
    "\n",
    "\n",
    "tracts10_shp = gpd.read_file('https://www2.census.gov/geo/tiger/TIGER2010/TRACT/2010/tl_2010_48_tract10.zip')\n",
    "tracts10_shp['cnty_geoid'] = tracts10_shp['STATEFP10'].astype(str) + tracts10_shp['COUNTYFP10'].astype(str)\n",
    "tracts10_shp['cnty_nm'] = tracts10_shp['cnty_geoid'].map(houmetro_cntys_swap)\n",
    "tracts10_shp.rename(columns={'GEOID10':'tract_geoid'},inplace=True)\n",
    "houtracts10_shp = tracts10_shp.loc[tracts10_shp['cnty_geoid'].isin(houmetro_fips_strs)]\n",
    "houtracts10_shp = houtracts10_shp[['cnty_geoid','cnty_nm','tract_geoid','geometry']]\n",
    "\n",
    "tracts20_shp = gpd.read_file('https://www2.census.gov/geo/tiger/TIGER2024/TRACT/tl_2024_48_tract.zip')\n",
    "tracts20_shp['cnty_geoid'] = tracts20_shp['STATEFP'].astype(str) + tracts20_shp['COUNTYFP'].astype(str)\n",
    "tracts20_shp['cnty_nm'] = tracts20_shp['cnty_geoid'].map(houmetro_cntys_swap)\n",
    "tracts20_shp.rename(columns={'GEOID':'tract_geoid'},inplace=True)\n",
    "houtracts20_shp = tracts20_shp.loc[tracts20_shp['cnty_geoid'].isin(houmetro_fips_strs)]\n",
    "houtracts20_shp = houtracts20_shp[['cnty_geoid','cnty_nm','tract_geoid','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(houtracts10_shp))\n",
    "print(houtracts10_shp.dtypes)\n",
    "display(houtracts10_shp.head(1))\n",
    "\n",
    "print(len(houtracts20_shp))\n",
    "print(houtracts20_shp.dtypes)\n",
    "display(houtracts20_shp.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# CDC asthma data\n",
    "########################################\n",
    "\n",
    "#load national data\n",
    "cdc = pd.read_csv('../data/source/CDC/PLACES__Local_Data_for_Better_Health__Census_Tract_Data_2024_release_20250103.csv')\n",
    "\n",
    "#restrict to just hou metro counties\n",
    "hou_cdc = cdc.loc[cdc['CountyFIPS'].isin(houmetro_fips_ints)]\n",
    "\n",
    "#delete cdc cause it's huge and we don't need it anymore\n",
    "del cdc\n",
    "\n",
    "#restrict to just asthma\n",
    "hou_asthma = hou_cdc.loc[hou_cdc['MeasureId'] == 'CASTHMA']\n",
    "\n",
    "#create correct type on tract_geoid\n",
    "hou_asthma['tract_geoid'] = hou_asthma['LocationName'].astype(str)\n",
    "\n",
    "#too many columns, reduce and rename\n",
    "rename_cols = {'Data_Value':'dv','TotalPopulation':'p','TotalPop18plus':'py',\n",
    "               'tract_geoid':'tract_geoid'}\n",
    "hou_asthma.rename(columns=rename_cols,inplace=True)\n",
    "hou_asthma = hou_asthma[list(rename_cols.values())]\n",
    "\n",
    "#connect to 2020 tracts - GEOID\n",
    "hou_asthma_geo = houtracts20_shp.merge(hou_asthma,on='tract_geoid',how='left')\n",
    "\n",
    "#get rid of nulls and save\n",
    "hou_asthma_geo_export = hou_asthma_geo.loc[~hou_asthma_geo['dv'].isna()]\n",
    "hou_asthma_geo_export.to_file('../GIS/for-map/cdc-asthma-houmetro.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max and min values for searchable map formatting\n",
    "print(len(hou_asthma_geo_export.loc[hou_asthma_geo_export['dv'].isna()]))\n",
    "print(hou_asthma_geo_export.dv.min())\n",
    "print(hou_asthma_geo_export.dv.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just making sure things look right\n",
    "print(len(hou_asthma_geo))\n",
    "print(hou_asthma_geo.columns)\n",
    "display(hou_asthma_geo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing valuse\n",
    "print(len(hou_asthma_geo.loc[hou_asthma_geo['dv'].isna()]))\n",
    "display(hou_asthma_geo.loc[hou_asthma_geo['dv'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# CDC life expectancy data\n",
    "########################################\n",
    "\n",
    "#load national data\n",
    "life_ex_us = pd.read_csv('../data/source/CDC/U.S._Life_Expectancy_at_Birth_by_State_and_Census_Tract_-_2010-2015.csv')\n",
    "\n",
    "#restrict to just hou metro counties\n",
    "life_ex_us['County'] = life_ex_us['County'].str.replace(' County','')\n",
    "hou_life = life_ex_us.loc[(life_ex_us['State'] == 'Texas')&(life_ex_us['County'].isin(houmetro_nms))]\n",
    "\n",
    "#delete us data cause we don't need it\n",
    "del life_ex_us\n",
    "\n",
    "#get rid of values that don't have tract numbers\n",
    "hou_life = hou_life.loc[~hou_life['Census Tract Number'].isna()]\n",
    "\n",
    "#creately format tract_geoid\n",
    "hou_life['tract_fips'] = hou_life['Census Tract Number'].apply(lambda x: f'{x:.2f}')\n",
    "hou_life['tract_fips'] = hou_life['tract_fips'].astype(str).str.replace('.','')\n",
    "hou_life['cnty_fips'] = hou_life['County'].map(houmetro_cntys)\n",
    "hou_life['tract_geoid'] = hou_life['cnty_fips'] + hou_life['tract_fips']\n",
    "\n",
    "#too many columns, reduce and rename\n",
    "rename_cols = {'Life Expectancy':'ex','Life Expectancy Range':'exr', \n",
    "               'Life Expectancy Standard Error':'exe','tract_geoid':'tract_geoid'}\n",
    "hou_life.rename(columns=rename_cols,inplace=True)\n",
    "hou_life = hou_life[list(rename_cols.values())]\n",
    "\n",
    "#connect to 2010 tracts - GEOID\n",
    "hou_life_geo = houtracts10_shp.merge(hou_life,on='tract_geoid')\n",
    "\n",
    "#get rid of nulls and save\n",
    "hou_life_geo_export = hou_life_geo.loc[~hou_life_geo['ex'].isna()]\n",
    "hou_life_geo_export.to_file('../GIS/for-map/cdc-lifeexpectancy-houmetro.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max and min values for searchable map formatting\n",
    "print(len(hou_life_geo_export.loc[hou_life_geo_export['ex'].isna()]))\n",
    "print(hou_life_geo_export.ex.min())\n",
    "print(hou_life_geo_export.ex.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just making sure they all join\n",
    "print('hou_life:',len(hou_life))\n",
    "print('hou_life_geo:',len(hou_life_geo))\n",
    "print(hou_life.columns)\n",
    "display(hou_life.loc[~hou_life['tract_geoid'].isin(list(hou_life_geo['tract_geoid'].unique()))].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# Poverty data\n",
    "########################################\n",
    "\n",
    "#load national data\n",
    "pov = pd.read_csv('../data/source/ACSST5Y2023.S1901_2025-01-03T110020/ACSST5Y2023.S1901-Data.csv')\n",
    "\n",
    "#drop the first row that's the hr column names\n",
    "pov = pov.iloc[1:]\n",
    "\n",
    "#create correct type on fields\n",
    "pov['tract_geoid'] = pov['GEO_ID'].str.replace('1400000US','')\n",
    "pov['cnty_geoid'] = pov['tract_geoid'].str[:5]\n",
    "pov['S1901_C01_012E'] = pd.to_numeric(pov['S1901_C01_012E'],errors='coerce')\n",
    "pov['S1901_C01_012M'] = pd.to_numeric(pov['S1901_C01_012M'],errors='coerce')\n",
    "\n",
    "#restrict to just hou metro counties\n",
    "hou_pov = pov.loc[pov['cnty_geoid'].isin(houmetro_fips_strs)]\n",
    "\n",
    "#delete cdc cause it's huge and we don't need it anymore\n",
    "del pov\n",
    "\n",
    "#too many columns, reduce and rename\n",
    "keep_cols = {'tract_geoid':'tract_geoid','S1901_C01_001E':'hh',\n",
    "             'S1901_C01_012E':'mi','S1901_C01_012M':'mimoe'}\n",
    "hou_pov = hou_pov[list(keep_cols.keys())]\n",
    "hou_pov.rename(columns=keep_cols,inplace=True)\n",
    "\n",
    "#connect to 2020 tracts - GEOID\n",
    "hou_pov_geo = houtracts20_shp.merge(hou_pov,on='tract_geoid',how='left')\n",
    "\n",
    "#save\n",
    "hou_pov_geo_export = hou_pov_geo.loc[~hou_pov_geo['mi'].isna()]\n",
    "hou_pov_geo_export.to_file('../GIS/for-map/census-hh-income-houmetro.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get max and min values for searchable map formatting\n",
    "print(len(hou_pov_geo_export.loc[hou_pov_geo_export['mi'].isna()]))\n",
    "print(hou_pov_geo_export.mi.min())\n",
    "print(hou_pov_geo_export.mi.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hou_pov))\n",
    "print(len(hou_pov_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just checking how many have outrageous MOE\n",
    "hou_pov['moe_share'] = (hou_pov['mimoe']/hou_pov['mi'])*100\n",
    "\n",
    "#share with moe above 30%\n",
    "print('Share with MOE over 30%:',(len(hou_pov.loc[hou_pov['moe_share']>29.99])/len(hou_pov))*100)\n",
    "\n",
    "display(hou_pov.sort_values('moe_share',ascending=False).head(20))\n",
    "display(hou_pov.sort_values('moe_share',ascending=True).head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
